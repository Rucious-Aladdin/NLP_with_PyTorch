{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/9TOu5rugdQFmjGTOY93h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcDXq1SfGkmj","executionInfo":{"status":"ok","timestamp":1709885887476,"user_tz":-540,"elapsed":3778,"user":{"displayName":"김수성","userId":"09570314636293598107"}},"outputId":"3e24bce0-7c9b-4b09-8bd3-31ba2aa2cd0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.6948, grad_fn=<MseLossBackward0>)\n"]}],"source":["# 3.3.1 MSE LOSS\n","\n","import torch\n","import torch.nn as nn\n","\n","mse_loss = nn.MSELoss()\n","outputs = torch.randn(3, 5, requires_grad=True)\n","targets = torch.randn(3, 5)\n","loss = mse_loss(outputs, targets)\n","print(loss)"]},{"cell_type":"markdown","source":["MSE에러는 (정답 - 예측값)의 제곱에 데이터수를 나눈 형태로 나타난다.\n","\n","$$L_{MSE}(y, \\hat{y})= \\frac{1}{n}\\sum_{i=1}^{n}{(y - \\hat{y})^2}$$\n","\n","일반적으로 출력과 타깃이 연속적인 실수값을 가지는 회귀문제에서 자주 활용된다."],"metadata":{"id":"OIxSZn25JAJo"}},{"cell_type":"code","source":["# 3.3.2 categorical Cross-Entropy-Loss\n","\n","import torch\n","import torch.nn as nn\n","\n","ce_loss = nn.CrossEntropyLoss()\n","output = torch.randn(3, 5, requires_grad=True) #(num_instances, num_classes)\n","softmax = nn.Softmax(dim = 1)\n","probabilities = softmax(outputs)\n","targets = torch.tensor([1, 0, 4], dtype=torch.int64) # <=> [0, 1, 0, 0, 0], [1, 0, 0, 0, 0], [0, 0, 0, 0, 1]\n","loss = ce_loss(outputs, targets) #(y, y_hat)\n","print(probabilities)\n","print(loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XmOSCV8OKLC2","executionInfo":{"status":"ok","timestamp":1709887000148,"user_tz":-540,"elapsed":5,"user":{"displayName":"김수성","userId":"09570314636293598107"}},"outputId":"750ce961-f424-4276-d143-f5c302799390"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.0855, 0.2337, 0.5130, 0.1004, 0.0674],\n","        [0.3511, 0.1600, 0.1004, 0.1115, 0.2770],\n","        [0.1727, 0.0580, 0.4556, 0.0967, 0.2170]], grad_fn=<SoftmaxBackward0>)\n","tensor(1.3427, grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"markdown","source":["지수함수의 값이 기하급수적으로 커지는 것을 막기위해서.. 분자분모에 최댓값을 빼줌.<br/><br/>\n","$$softmax(x_i)=\\frac{e^{x_i}-e^{x_{max}}}{\\sum_{j = 1}^{k}{e^{x_j}}-e^{x_{max}}}$$\n","\n","이후 cross-entropy는 위와 같은 공식으로 유도되며, 정답은 대부분의 경우에 one-hot vector로 주어지므로, $y_i$의 값은 타겟인 클래스를 제외하고 모조리 0이된다. 결국 손실함수의 값은 예측클래스에 대한 로그확률로써 간소화된다.\n","\n","$$L_{cross-entropy}(y, \\hat{y}) = -y_i\\sum_{i=1}^{n}{log(\\hat{y_i})}=-log(\\hat{y_j})=-\\hat{p}$$"],"metadata":{"id":"fNdqM6Q9Nh3f"}},{"cell_type":"code","source":["# 3.3.3 binary cross-entropy loss\n","\n","bce_loss = nn.BCELoss()\n","sigmoid = nn.Sigmoid()\n","probabilities = sigmoid(torch.randn(4, 1, requires_grad=True))\n","targets = torch.tensor([1, 0, 1, 0], dtype=torch.float32).view(4, 1)\n","loss = bce_loss(probabilities, targets)\n","print(probabilities)\n","print(loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"muKzARLwLUfR","executionInfo":{"status":"ok","timestamp":1709886726071,"user_tz":-540,"elapsed":552,"user":{"displayName":"김수성","userId":"09570314636293598107"}},"outputId":"bfbe997d-0d7c-44e2-f0ea-7c5565be8910"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2607],\n","        [0.3685],\n","        [0.3022],\n","        [0.4083]], grad_fn=<SigmoidBackward0>)\n","tensor(0.8814, grad_fn=<BinaryCrossEntropyBackward0>)\n"]}]}]}