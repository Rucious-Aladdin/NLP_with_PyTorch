{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOrVr3KDUhr/1YBE9gNQdP3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["def describe(x):\n","  print(\"x.type:\", x.type)\n","  print(\"x.shape:\", x.shape)\n","  print(\"x.value:\", x)"],"metadata":{"id":"-7sgVAqms6sw","executionInfo":{"status":"ok","timestamp":1709878687497,"user_tz":-540,"elapsed":350,"user":{"displayName":"김수성","userId":"09570314636293598107"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":16,"metadata":{"id":"04eNdGcpkoic","executionInfo":{"status":"ok","timestamp":1709878824074,"user_tz":-540,"elapsed":389,"user":{"displayName":"김수성","userId":"09570314636293598107"}}},"outputs":[],"source":["# 3-1 Perceptrons\n","\n","import torch\n","import torch.nn as nn\n","\n","class Perceptron(nn.Module):\n","  def __init__(self, input_dim):\n","    super(Perceptron, self).__init__()\n","    self.fc1 = nn.Linear(input_dim, 1)\n","\n","  def forward(self, x_in): #x_in --> torch.Tensor, x_in.shape(batch, num_features)\n","    return torch.sigmoid(self.fc1(x_in)).squeeze() # x_out --> torch.Tensor, x_out.shape(batch, )"]},{"cell_type":"markdown","source":["$$y=f(\\mathbf{wx}+b)$$ <br/>\n","$\\mathbf{x}$는 vector, $\\mathbf{x}$와 $\\mathbf{w}$의 곱은 dot product에 해당(내적의 일종)\n","또한 $wx+b$와 같은 변환을 Affine Transformation이라고 부름.\n","(선형 대수적으로 일차 선형변환 이후 가변적인 가중치/(offset)값을 더해주는 것이라고도 볼 수 있음.)\n","https://eunho5751.tistory.com/37\n","\n"],"metadata":{"id":"C0yLrQkpktHF"}},{"cell_type":"code","source":["import torch\n","\n","# x_in = (batch, num_features) --> (10, 3)\n","x_in = torch.randn(10, 3)\n","describe(x_in)\n","\n","test_perceptrons = Perceptron(3)\n","x_out = test_perceptrons.forward(x_in)\n","describe(x_out)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M5FxsLPtsvaR","executionInfo":{"status":"ok","timestamp":1709878825121,"user_tz":-540,"elapsed":11,"user":{"displayName":"김수성","userId":"09570314636293598107"}},"outputId":"5869fb07-3c49-479e-bf71-bf011092c049"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["x.type: <built-in method type of Tensor object at 0x7dc4562ac950>\n","x.shape: torch.Size([10, 3])\n","x.value: tensor([[ 0.1273,  1.3413, -1.3047],\n","        [ 0.8624, -0.0507,  0.3177],\n","        [-0.6890, -0.6839,  2.7439],\n","        [ 1.5204, -0.9703,  0.0295],\n","        [ 0.8478,  0.5709, -0.4015],\n","        [ 0.1300,  0.3107,  0.9335],\n","        [-1.2491, -2.1772,  0.7902],\n","        [-0.0945,  0.2581,  0.6456],\n","        [-0.9655,  0.5548,  1.7017],\n","        [-0.0833, -3.3311,  2.8082]])\n","x.type: <built-in method type of Tensor object at 0x7dc3c4be4770>\n","x.shape: torch.Size([10])\n","x.value: tensor([0.5898, 0.7153, 0.6948, 0.7436, 0.6882, 0.6885, 0.5304, 0.6557, 0.6352,\n","        0.7189], grad_fn=<SqueezeBackward0>)\n"]}]}]}